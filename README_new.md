# MLflow Server Setup

This repository contains MLflow server setups for the Pavement Classification project, organized into separate local and production environments.

## ğŸ“ Project Structure

```
mlflow-server/
â”œâ”€â”€ local/                    # Local development setup
â”‚   â”œâ”€â”€ model_7_local.py     # Local model training script
â”‚   â”œâ”€â”€ config_local.py      # Local configuration
â”‚   â”œâ”€â”€ README_local_model.md # Local setup documentation
â”‚   â”œâ”€â”€ start_simple_mlflow.sh # Simple MLflow server start
â”‚   â”œâ”€â”€ stop_simple_mlflow.sh  # Simple MLflow server stop
â”‚   â”œâ”€â”€ docker-compose.local.yml # Docker local setup (optional)
â”‚   â””â”€â”€ Dockerfile.local     # Local Docker image (optional)
â”œâ”€â”€ production/              # Production/AWS setup
â”‚   â”œâ”€â”€ docker-compose.yml   # Production Docker setup
â”‚   â”œâ”€â”€ Dockerfile           # Production Docker image
â”‚   â””â”€â”€ scripts/             # Production scripts
â”‚       â”œâ”€â”€ setup_server.sh  # EC2 setup automation
â”‚       â”œâ”€â”€ start_mlflow.sh  # Start production MLflow
â”‚       â””â”€â”€ check_s3_access.sh # S3 connectivity check
â”œâ”€â”€ mlflow-artifacts/        # Local artifact storage (created)
â”œâ”€â”€ mlruns/                  # Local runs storage (created)
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### ğŸ  Local Development (Recommended for Development)

**Simple Setup** (No Docker required):
```bash
cd local/
./start_simple_mlflow.sh

# Run your model training
python model_7_local.py

# Access MLflow UI at http://localhost:5005
```

**Models stored in**: `../mlflow-artifacts/` directory

### â˜ï¸ Production/AWS Setup

For production deployment with S3 storage:
```bash
cd production/
./scripts/setup_server.sh
./scripts/start_mlflow.sh

# Access at http://<EC2_PUBLIC_IP>:5000
```

**Models stored in**: S3 bucket (`s3://mlflow-pavement-classification/`)

## ğŸ”§ Configuration

### Local Development
- **Configuration**: `local/config_local.py`
- **MLflow URI**: `http://localhost:5005`
- **Backend Store**: File-based (`./mlruns/`)
- **Artifact Store**: Local directory (`./mlflow-artifacts/`)

### Production
- **MLflow URI**: `http://<EC2_PUBLIC_IP>:5000`
- **Backend Store**: MySQL database
- **Artifact Store**: S3 bucket

## ğŸ“Š Features

### Local Setup Benefits
- âœ… No AWS costs
- âœ… No internet required
- âœ… Fast artifact storage
- âœ… Easy debugging
- âœ… Perfect for development
- âœ… No Docker complications

### Production Setup Benefits
- âœ… Scalable MySQL backend
- âœ… S3 artifact storage
- âœ… Production-ready
- âœ… Team collaboration
- âœ… Persistent storage

## ğŸ› ï¸ Switching Between Setups

### From Local to Production
1. Train and validate your model locally
2. Update data paths and MLflow URI for production
3. Deploy to EC2 using production setup

### From Production to Local
1. Download model artifacts from S3 if needed
2. Use local setup for development and debugging

## ğŸ“š Documentation

- **Local Setup**: See `local/README_local_model.md`
- **Production Setup**: See `production/` directory
- **Model Training**: Use `local/model_7_local.py` for local development

## ğŸ¯ Recommended Workflow

1. **Development**: Use local setup for model development and testing
2. **Validation**: Test with small datasets locally
3. **Production**: Deploy to AWS for full-scale training and team collaboration

Choose the setup that best fits your current needs!
