# ğŸ³ Containerized MLflow Training

This setup runs both MLflow server and training scripts in Docker containers, eliminating artifact logging issues and providing a consistent environment.

## ğŸš€ Quick Start

### 1. Start MLflow Server
```bash
./start_mlflow_local.sh
```

### 2. Run Containerized Training
```bash
./run_training.sh train
```

### 3. View Results
Open http://localhost:5005 to see your experiments and artifacts!

## ğŸ“ File Structure

```
local/
â”œâ”€â”€ Dockerfile.training          # Training container definition
â”œâ”€â”€ docker-compose.local.yml     # Updated with training service
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ config_containerized.py      # Container-specific config
â”œâ”€â”€ model_7_containerized.py     # Containerized training script
â”œâ”€â”€ run_training.sh             # Training orchestration script
â””â”€â”€ README_CONTAINERIZED.md     # This file
```

## ğŸ› ï¸ Available Commands

### Training Commands
```bash
# Run default training
./run_training.sh train

# Run specific script
./run_training.sh train model_7_containerized.py

# Just build the training image
./run_training.sh build

# Clean up containers and images
./run_training.sh cleanup

# Show help
./run_training.sh help
```

### MLflow Server Commands
```bash
# Start MLflow server
./start_mlflow_local.sh

# Stop MLflow server (preserves data)
./stop_mlflow_local.sh

# Clean all data (destructive!)
./clean_all_data.sh
```

## ğŸ”§ How It Works

### Container Architecture
1. **MLflow Server Container**: Runs MLflow UI and API
2. **MySQL Container**: Stores experiment metadata
3. **Training Container**: Runs your training scripts

### Network Communication
- All containers run in the same Docker network
- Training container connects to MLflow server via `http://mlflow-server-local:5000`
- Artifacts are shared via mounted volumes

### Volume Mapping
- `../mlflow-artifacts/` â†’ Container artifacts storage
- `../data/` â†’ Shared data directory
- `mysql_data_local` â†’ MySQL database persistence

## âœ… Benefits

### âœ… **Artifact Logging Fixed**
- No more "Read-only file system" errors
- All containers share the same file system access
- Proper artifact server integration

### âœ… **Consistent Environment**
- Same Python/library versions everywhere
- No dependency conflicts with host system
- Reproducible across different machines

### âœ… **Easy Deployment**
- Everything runs with one command
- No need to install Python packages on host
- Self-contained and portable

### âœ… **Data Persistence**
- Experiments and artifacts preserved between runs
- MySQL database persists in Docker volume
- Easy backup and restore

## ğŸ§ª Testing the Setup

### 1. Verify MLflow Server
```bash
curl http://localhost:5005
```

### 2. Run Test Training
```bash
./run_training.sh train
```

### 3. Check Artifacts
- Go to http://localhost:5005
- Navigate to your experiment
- Verify artifacts are logged correctly

## ğŸ” Troubleshooting

### Training Container Won't Start
```bash
# Check if MLflow server is running
curl http://localhost:5005

# Rebuild training image
./run_training.sh build

# Check Docker logs
docker-compose -f docker-compose.local.yml logs training
```

### Artifact Logging Issues
```bash
# Check volume mounts
docker-compose -f docker-compose.local.yml config

# Verify network connectivity
docker-compose -f docker-compose.local.yml exec training ping mlflow-server-local
```

### Clean Start
```bash
# Stop everything
./stop_mlflow_local.sh

# Clean up training containers
./run_training.sh cleanup

# Start fresh
./start_mlflow_local.sh
./run_training.sh train
```

## ğŸ¯ Next Steps

1. **Customize Training**: Modify `model_7_containerized.py` for your needs
2. **Add More Models**: Create additional training scripts
3. **GPU Support**: Update Dockerfile for CUDA if needed
4. **Production**: Use this as base for production deployments

## ğŸ“Š Expected Results

After running training, you should see:
- âœ… Experiment logged in MLflow UI
- âœ… Training curves artifact uploaded
- âœ… Model artifacts saved
- âœ… All metrics tracked properly
- âœ… No file system errors!
